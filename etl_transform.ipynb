{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5bd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FULL DATA BEFORE TRANSFORMATIONS ---\n",
      "   order_id customer_name product  quantity  unit_price  order_date region\n",
      "0         1         Diana  Tablet       NaN       500.0  2024-01-20  South\n",
      "1         2           Eve  Laptop       NaN         NaN  2024-04-29  North\n",
      "2         3       Charlie  Laptop       2.0       250.0  2024-01-08    NaN\n",
      "3         4           Eve  Laptop       2.0       750.0  2024-01-07   West\n",
      "4         5           Eve  Tablet       3.0         NaN  2024-03-07  South\n",
      "FULL DATA: Removed 1 duplicate rows.\n",
      "FULL DATA: Missing values before:\n",
      "order_id          0\n",
      "customer_name     1\n",
      "product           0\n",
      "quantity         26\n",
      "unit_price       35\n",
      "order_date        1\n",
      "region           25\n",
      "dtype: int64\n",
      "FULL DATA: Missing values after:\n",
      "order_id         0\n",
      "customer_name    0\n",
      "product          0\n",
      "quantity         0\n",
      "unit_price       0\n",
      "order_date       0\n",
      "region           0\n",
      "dtype: int64\n",
      "FULL DATA: Added 'total_price' column.\n",
      "FULL DATA: Converted 'order_date' to datetime.\n",
      "FULL DATA: Categorized 'spending_category'.\n",
      "\n",
      "--- FULL DATA AFTER TRANSFORMATIONS ---\n",
      "    order_id customer_name  product  quantity  unit_price order_date region  \\\n",
      "3          4           Eve   Laptop       2.0       750.0 2024-01-07   West   \n",
      "6          7       Charlie  Monitor       2.0       750.0 2024-02-02   West   \n",
      "9         10           Eve  Monitor       1.0       500.0 2024-02-28  North   \n",
      "11        12       Charlie   Tablet       2.0       750.0 2024-03-26   East   \n",
      "12        13         Frank   Tablet       1.0       750.0 2024-04-28   West   \n",
      "\n",
      "    total_price spending_category  \n",
      "3        1500.0         Very High  \n",
      "6        1500.0         Very High  \n",
      "9         500.0            Medium  \n",
      "11       1500.0         Very High  \n",
      "12        750.0              High  \n",
      "\n",
      "--- INCREMENTAL DATA BEFORE TRANSFORMATIONS ---\n",
      "   order_id customer_name product  quantity  unit_price  order_date   region\n",
      "0       101         Alice  Laptop       NaN       900.0  2024-05-09  Central\n",
      "1       102           NaN  Laptop       1.0       300.0  2024-05-07  Central\n",
      "2       103           NaN  Laptop       1.0       600.0  2024-05-04  Central\n",
      "3       104           NaN  Tablet       NaN       300.0  2024-05-26  Central\n",
      "4       105         Heidi  Tablet       2.0       600.0  2024-05-21    North\n",
      "INCREMENTAL DATA: Removed 0 duplicate rows.\n",
      "INCREMENTAL DATA: Missing values before:\n",
      "order_id         0\n",
      "customer_name    6\n",
      "product          0\n",
      "quantity         4\n",
      "unit_price       0\n",
      "order_date       0\n",
      "region           2\n",
      "dtype: int64\n",
      "INCREMENTAL DATA: Missing values after:\n",
      "order_id         0\n",
      "customer_name    0\n",
      "product          0\n",
      "quantity         0\n",
      "unit_price       0\n",
      "order_date       0\n",
      "region           0\n",
      "dtype: int64\n",
      "INCREMENTAL DATA: Added 'total_price' column.\n",
      "INCREMENTAL DATA: Converted 'order_date' to datetime.\n",
      "INCREMENTAL DATA: Categorized 'spending_category'.\n",
      "\n",
      "--- INCREMENTAL DATA AFTER TRANSFORMATIONS ---\n",
      "   order_id customer_name product  quantity  unit_price order_date   region  \\\n",
      "4       105         Heidi  Tablet       2.0       600.0 2024-05-21    North   \n",
      "8       109         Grace  Laptop       2.0       600.0 2024-05-29  Central   \n",
      "\n",
      "   total_price spending_category  \n",
      "4       1200.0         Very High  \n",
      "8       1200.0         Very High  \n",
      "✅ Transformations complete and files saved.\n"
     ]
    }
   ],
   "source": [
    "# ETL Midterm - Transform Phase\n",
    "# Author: <Your First Name>\n",
    "# Student ID Last 3 Digits: <IDLast3Digits>\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "# transformed directory       \n",
    "os.makedirs(\"transformed\", exist_ok=True)\n",
    "\n",
    "# Load the raw data\n",
    "raw_df = pd.read_csv(\"data/raw_data.csv\")\n",
    "incremental_df = pd.read_csv(\"data/incremental_data.csv\")\n",
    "\n",
    "# Helper function to apply 4+ transformations\n",
    "def transform(df, label=\"\"):\n",
    "    df = df.copy()\n",
    "\n",
    "    print(f\"\\n--- {label} BEFORE TRANSFORMATIONS ---\")\n",
    "    print(df.head())\n",
    "\n",
    "    # 1. Remove duplicates\n",
    "    before = df.shape[0]\n",
    "    df = df.drop_duplicates()\n",
    "    after = df.shape[0]\n",
    "    print(f\"{label}: Removed {before - after} duplicate rows.\")\n",
    "\n",
    "    # 2. Handle missing values (drop rows with any NaN)\n",
    "    before_na = df.isnull().sum()\n",
    "    df = df.dropna()\n",
    "    after_na = df.isnull().sum()\n",
    "    print(f\"{label}: Missing values before:\\n{before_na}\")\n",
    "    print(f\"{label}: Missing values after:\\n{after_na}\")\n",
    "\n",
    "    # 3. Add total_price = quantity * unit_price (only if both columns exist)\n",
    "    if 'quantity' in df.columns and 'unit_price' in df.columns:\n",
    "        try:\n",
    "            df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')\n",
    "            df['unit_price'] = pd.to_numeric(df['unit_price'], errors='coerce')\n",
    "            df['total_price'] = df['quantity'] * df['unit_price']\n",
    "            print(f\"{label}: Added 'total_price' column.\")\n",
    "        except Exception as e:\n",
    "            print(f\"{label}: Could not calculate total_price: {e}\")\n",
    "\n",
    "    # 4. Convert order_date column to datetime (only if it exists)\n",
    "    if 'order_date' in df.columns:\n",
    "        df['order_date'] = pd.to_datetime(df['order_date'], errors='coerce')\n",
    "        print(f\"{label}: Converted 'order_date' to datetime.\")\n",
    "\n",
    "    # 5. Optional categorization: spending_category\n",
    "    if 'total_price' in df.columns:\n",
    "        df['spending_category'] = pd.cut(\n",
    "            df['total_price'],\n",
    "            bins=[0, 100, 500, 1000, float('inf')],\n",
    "            labels=['Low', 'Medium', 'High', 'Very High']\n",
    "        )\n",
    "        print(f\"{label}: Categorized 'spending_category'.\")\n",
    "\n",
    "    print(f\"\\n--- {label} AFTER TRANSFORMATIONS ---\")\n",
    "    print(df.head())\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply transformations\n",
    "transformed_full = transform(raw_df, label=\"FULL DATA\")\n",
    "transformed_incremental = transform(incremental_df, label=\"INCREMENTAL DATA\")\n",
    "\n",
    "# Save results\n",
    "transformed_full.to_csv(\"transformed/transformed_full.csv\", index=False)\n",
    "transformed_incremental.to_csv(\"transformed/transformed_incremental.csv\", index=False)\n",
    "\n",
    "print(\"✅ Transformations complete and files saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
